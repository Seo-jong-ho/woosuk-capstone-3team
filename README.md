# 캡스톤 디자인 3팀 - MLKit을 활용한 다양한 기능 구현

## 팀 개요 및 구성
**팀장:** 서종호  
**팀원:**  
- **서종호:** AR 기능 개발 및 tensorflow 모델 재구성, 팀장 역할 수행  
- **유종현:** 자세 추정, 얼굴 감지 기능 개발  
- **김재훈:** 텍스트 감지 기능 개발  
- **김준우:** 동작 감지 기능 개발  

---

## 프로젝트 개요
본 프로젝트는 MLKit을 활용하여 다양한 기능을 제공하는 안드로이드 어플리케이션을 개발하는 것을 목표로 하였습니다.  
사용자 데이터를 분석하여 자세, 얼굴, 텍스트, 동작 감지 및 AR 기술을 통합적으로 구현하였습니다

### 주요 기능
1. **자세 추정 및 얼굴 감지**: 사용자 관절 및 얼굴 위치를 실시간으로 추적하여 자세를 분석 및 평가.  
2. **텍스트 감지**: 이미지 내 텍스트를 인식하여 데이터화.  
3. **동작 감지**: 사용자의 움직임을 감지하여 동작 패턴 분석.  
4. **AR 기능**: ARCore를 활용한 증강현실(AR) 경험 제공 및 이미지 시각화.

---

## 개발 환경
- **IDE:** Android Studio  
- **라이브러리 및 기술 스택:**  
  - **MLKit**: 자세 추정, 얼굴 감지, 텍스트 감지, 동작 감지 구현  
  - **AWS Server**: 데이터 저장 및 API 서비스  
  - **TensorFlow**: 모델 학습 및 최적화  

---

## 프로젝트 성과
- MLKit의 다양한 기능(자세, 얼굴, 텍스트, 동작 감지)을 통합적으로 구현하여 실시간 분석 가능.  
- ARCore를 활용하여 3D 시각화를 성공적으로 구현, 사용자 경험을 개선.
- 안드로이드 스튜디오를 활용하여 모바일 애플리케이션 특성에 맞는 최적화된 UI/UX를 설계하고, 다양한 디바이스에서 원활히 동작하도록 개발.

---

## 실행 결과
실행 결과는 프로젝트 폴더 내 포함된 **`readme_team3.pptx`** 파일을 통해 확인할 수 있습니다.  

---

## 기대 효과
- 실시간 데이터 분석 및 시각화를 통해 다양한 응용 가능성 확인 (예: 헬스케어, 콘텐츠 제작).  
